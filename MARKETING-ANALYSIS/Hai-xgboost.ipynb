{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":31,"outputs":[{"output_type":"stream","text":"/kaggle/input/open-shopee-code-league-marketing-analytics/users.csv\n/kaggle/input/open-shopee-code-league-marketing-analytics/sample_submission_0_1.csv\n/kaggle/input/open-shopee-code-league-marketing-analytics/train.csv\n/kaggle/input/open-shopee-code-league-marketing-analytics/test.csv\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"user_df = pd.read_csv('/kaggle/input/open-shopee-code-league-marketing-analytics/users.csv')\nsample_submission_df = pd.read_csv('/kaggle/input/open-shopee-code-league-marketing-analytics/sample_submission_0_1.csv')\ntrain_df = pd.read_csv('/kaggle/input/open-shopee-code-league-marketing-analytics/train.csv')\ntest_df = pd.read_csv('/kaggle/input/open-shopee-code-league-marketing-analytics/test.csv')","execution_count":83,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Additional libraries\nimport re\nimport networkx\nimport sklearn\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import classification_report, matthews_corrcoef, accuracy_score\nfrom xgboost import XGBRFClassifier","execution_count":84,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. Preprocessing\n0. Utilities\n1. User\n2. Train\n3. Test"},{"metadata":{},"cell_type":"markdown","source":"## 1.0. Utilities"},{"metadata":{"trusted":true},"cell_type":"code","source":"def is_never (string):\n    if (re.search('Never',string)):\n        return int(1)\n    else: \n        return int(0)\n    \ndef process_categorical(df, col_name, prefix):\n    one_hot = pd.get_dummies(df[col_name],prefix=prefix,prefix_sep='_',dtype=int)\n    return one_hot\n\ndef process_numerical_data(df, numerical_cols, drop_numerical_columns):\n#     sacalar = MinMaxScaler()\n    sacalar = StandardScaler() #if using StandardScaler\n    scale_numerical_cols = list(set(numerical_cols)-set(drop_numerical_columns))\n    df_numerical = sacalar.fit_transform(df[scale_numerical_cols])\n    df_numerical = pd.DataFrame(df_numerical,columns=scale_numerical_cols)\n    return df_numerical\n\ndef convert_rate10(value):\n    return float(value/10)\n\ndef convert_rate30(value):\n    return float(value/30)\n\ndef convert_rate60(value):\n    return float(value/60)\n\ndef evaluate_model(model, X_valid, y_valid, metric=accuracy_score):\n    y_pred = model.predict(X_valid)\n    return metric(y_valid, y_pred)","execution_count":85,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.1. User"},{"metadata":{"trusted":true},"cell_type":"code","source":"user_df = pd.read_csv('/kaggle/input/open-shopee-code-league-marketing-analytics/users.csv')","execution_count":86,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"user_df.info()","execution_count":87,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 127886 entries, 0 to 127885\nData columns (total 6 columns):\n #   Column   Non-Null Count   Dtype  \n---  ------   --------------   -----  \n 0   user_id  127886 non-null  int64  \n 1   attr_1   78987 non-null   float64\n 2   attr_2   127439 non-null  float64\n 3   attr_3   127886 non-null  float64\n 4   age      78987 non-null   float64\n 5   domain   127886 non-null  object \ndtypes: float64(4), int64(1), object(1)\nmemory usage: 5.9+ MB\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# attr_1 and attr_2: temporary drop\n# user_df = user_df.drop([\"attr_1\",\"attr_2\"],axis = 1)\n\n# # attr_1\nattr1_nan = user_df['attr_1'].isna()\nuser_df.loc[attr1_nan, 'attr_1'] = np.random.randint(2, size=attr1_nan.sum())\nuser_df['attr_1'] = user_df['attr_1'].astype('int64')\nuser_attr_1 = process_categorical(user_df, \"attr_1\", \"attr_1\")\n\n# # attr_2\nattr2_nan = user_df['attr_2'].isna()\nuser_df.loc[attr2_nan, 'attr_2'] = np.random.randint(2, size=attr2_nan.sum())\nuser_df['attr_2'] = user_df['attr_2'].astype('int64')\nuser_attr_2 = process_categorical(user_df, \"attr_2\", \"attr_2\")\n\n# attr_3\nuser_attr_3 = process_categorical(user_df, \"attr_3\", \"attr_3\")\n\n# age\nage_nan = user_df['age'].isna()\nuser_df.loc[age_nan, 'age'] = np.round(np.random.uniform(15, 65, size=age_nan.sum()),0)\n\n# domain\nuser_domain = process_categorical(user_df, \"domain\", \"domain\")","execution_count":89,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# merge into new user_df\nnew_user_df = pd.concat([\n    user_df['user_id'],\n    user_df['age'], \n#     user_attr_1, \n#     user_attr_2, \n    user_attr_3, \n    user_domain\n                        ], axis=1)\nnew_user_df.info()","execution_count":91,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 127886 entries, 0 to 127885\nData columns (total 18 columns):\n #   Column                  Non-Null Count   Dtype  \n---  ------                  --------------   -----  \n 0   user_id                 127886 non-null  int64  \n 1   age                     127886 non-null  float64\n 2   attr_3_0.0              127886 non-null  int64  \n 3   attr_3_1.0              127886 non-null  int64  \n 4   attr_3_2.0              127886 non-null  int64  \n 5   attr_3_3.0              127886 non-null  int64  \n 6   attr_3_4.0              127886 non-null  int64  \n 7   domain_@163.com         127886 non-null  int64  \n 8   domain_@gmail.com       127886 non-null  int64  \n 9   domain_@hotmail.com     127886 non-null  int64  \n 10  domain_@icloud.com      127886 non-null  int64  \n 11  domain_@live.com        127886 non-null  int64  \n 12  domain_@outlook.com     127886 non-null  int64  \n 13  domain_@qq.com          127886 non-null  int64  \n 14  domain_@rocketmail.com  127886 non-null  int64  \n 15  domain_@yahoo.com       127886 non-null  int64  \n 16  domain_@ymail.com       127886 non-null  int64  \n 17  domain_other            127886 non-null  int64  \ndtypes: float64(1), int64(17)\nmemory usage: 17.6 MB\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## 1.2. Train"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/open-shopee-code-league-marketing-analytics/train.csv')","execution_count":92,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.info()","execution_count":93,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 73539 entries, 0 to 73538\nData columns (total 18 columns):\n #   Column                       Non-Null Count  Dtype \n---  ------                       --------------  ----- \n 0   country_code                 73539 non-null  int64 \n 1   grass_date                   73539 non-null  object\n 2   user_id                      73539 non-null  int64 \n 3   subject_line_length          73539 non-null  int64 \n 4   last_open_day                73539 non-null  object\n 5   last_login_day               73539 non-null  object\n 6   last_checkout_day            73539 non-null  object\n 7   open_count_last_10_days      73539 non-null  int64 \n 8   open_count_last_30_days      73539 non-null  int64 \n 9   open_count_last_60_days      73539 non-null  int64 \n 10  login_count_last_10_days     73539 non-null  int64 \n 11  login_count_last_30_days     73539 non-null  int64 \n 12  login_count_last_60_days     73539 non-null  int64 \n 13  checkout_count_last_10_days  73539 non-null  int64 \n 14  checkout_count_last_30_days  73539 non-null  int64 \n 15  checkout_count_last_60_days  73539 non-null  int64 \n 16  open_flag                    73539 non-null  int64 \n 17  row_id                       73539 non-null  int64 \ndtypes: int64(14), object(4)\nmemory usage: 10.1+ MB\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# country\ntrain_df_country = process_categorical(train_df, \"country_code\", \"country\")\n\n# convert grass_date and create email_sent_dayofweek\ntrain_df['grass_date'] = pd.to_datetime(train_df['grass_date'])\ntrain_df['email_sent_dayofweek'] = train_df['grass_date'].dt.dayofweek\ntrain_df_weekday = process_categorical(train_df, \"email_sent_dayofweek\", \"email_sent_weekday\")\n\n# never_open, never_login, never_checkout\ntrain_df['never_open'] = train_df['last_open_day'].apply(is_never)\ntrain_df['never_login'] = train_df['last_login_day'].apply(is_never)\ntrain_df['never_checkout'] = train_df['last_checkout_day'].apply(is_never)\n\n# replace never_open, never_login, never_checkout | last_open_day, last_login_day, last_checkout_day\ntrain_df['last_open_day'] = train_df['last_open_day'].replace(['Never open'],'1600')\ntrain_df['last_login_day'] = train_df['last_login_day'].replace(['Never login'],'36000')\ntrain_df['last_checkout_day'] = train_df['last_checkout_day'].replace(['Never checkout'],'3000')\n\ntrain_df['last_open_day'] = train_df['last_open_day'].astype('int64')\ntrain_df['last_login_day'] = train_df['last_login_day'].astype('int64')\ntrain_df['last_checkout_day'] = train_df['last_checkout_day'].astype('int64')\n\n# open_count_last_10_days, open_count_last_30_days, open_count_last_60_days\ntrain_df['open_count_rate_last_10_days'] = train_df['open_count_last_10_days'].apply(convert_rate10)\ntrain_df['open_count_rate_last_30_days'] = train_df['open_count_last_30_days'].apply(convert_rate30)\ntrain_df['open_count_rate_last_60_days'] = train_df['open_count_last_60_days'].apply(convert_rate60)\n\ntrain_df['open_count_further_20_days'] = train_df['open_count_last_30_days'] - train_df['open_count_last_10_days']\ntrain_df['open_count_further_30_days'] = train_df['open_count_last_60_days'] - train_df['open_count_last_30_days']\n\n# login_count_last_10_days, login_count_last_30_days, login_count_last_60_days\ntrain_df['login_count_rate_last_10_days'] = train_df['login_count_last_10_days'].apply(convert_rate10)\ntrain_df['login_count_rate_last_30_days'] = train_df['login_count_last_30_days'].apply(convert_rate30)\ntrain_df['login_count_rate_last_60_days'] = train_df['login_count_last_60_days'].apply(convert_rate60)\n\ntrain_df['login_count_further_20_days'] = train_df['login_count_last_30_days'] - train_df['login_count_last_10_days']\ntrain_df['login_count_further_30_days'] = train_df['login_count_last_60_days'] - train_df['login_count_last_30_days']\n\n# checkout_count_last_10_days, checkout_count_last_30_days, checkout_count_last_60_days\ntrain_df['checkout_count_rate_last_10_days'] = train_df['checkout_count_last_10_days'].apply(convert_rate10)\ntrain_df['checkout_count_rate_last_30_days'] = train_df['checkout_count_last_30_days'].apply(convert_rate30)\ntrain_df['checkout_count_rate_last_60_days'] = train_df['checkout_count_last_60_days'].apply(convert_rate60)\n\ntrain_df['checkout_count_further_20_days'] = train_df['checkout_count_last_30_days'] - train_df['checkout_count_last_10_days']\ntrain_df['checkout_count_further_30_days'] = train_df['checkout_count_last_60_days'] - train_df['checkout_count_last_30_days']\n\n# row_id: drop\ntrain_df = train_df.drop([\"row_id\"],axis = 1)\n\n# open_flag: label\nopen_flag = train_df['open_flag']","execution_count":94,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_num = ['subject_line_length',\n                'last_open_day', 'last_login_day', 'last_checkout_day',\n                'open_count_last_10_days',#'open_count_last_30_days','open_count_last_60_days',\n                'open_count_further_20_days','open_count_further_30_days',\n                'login_count_last_10_days',#'login_count_last_30_days','login_count_last_60_days',\n                'login_count_further_20_days','login_count_further_30_days',\n                'checkout_count_last_10_days',#'checkout_count_last_30_days','checkout_count_last_60_days',\n                'checkout_count_further_20_days','checkout_count_further_30_days',\n               ]\ndrop_numerical_columns = []\ntrain_df_numerical = process_numerical_data(train_df,_num,drop_numerical_columns)\n# train_df_numerical","execution_count":95,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# merge with user_df\nnew_train_df = pd.concat([train_df_country, train_df_weekday, \n                          train_df[[\n                              'user_id',\n#                               'subject_line_length',\n#                               'last_open_day','last_login_day','last_checkout_day',\n                              'never_open','never_login','never_checkout',\n                              'open_count_rate_last_10_days','open_count_rate_last_30_days','open_count_rate_last_60_days',\n                              'login_count_rate_last_10_days','login_count_rate_last_30_days','login_count_rate_last_60_days',\n                              'checkout_count_rate_last_10_days','checkout_count_rate_last_30_days','checkout_count_rate_last_60_days',\n#                               'open_count_last_10_days','open_count_last_30_days','open_count_last_60_days',\n#                               'open_count_further_20_days','open_count_further_30_days',\n#                               'login_count_last_10_days','login_count_last_30_days','login_count_last_60_days',\n#                               'login_count_further_20_days','login_count_further_30_days',\n#                               'checkout_count_last_10_days','checkout_count_last_30_days','checkout_count_last_60_days',\n#                               'checkout_count_further_20_days','checkout_count_further_30_days',\n                                   ]],\n                          train_df_numerical\n                         ], axis=1)\nnew_train_df = new_train_df.merge(new_user_df, how='left', left_on='user_id', right_on='user_id')\nnew_train_df = new_train_df.drop([\"user_id\"], axis=1)\nnew_train_df = pd.concat([new_train_df, train_df['open_flag']], axis=1)\nnew_train_df = new_train_df.dropna(axis=0)","execution_count":96,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_train_df.info()","execution_count":97,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nInt64Index: 73539 entries, 0 to 73538\nData columns (total 57 columns):\n #   Column                            Non-Null Count  Dtype  \n---  ------                            --------------  -----  \n 0   country_1                         73539 non-null  int64  \n 1   country_2                         73539 non-null  int64  \n 2   country_3                         73539 non-null  int64  \n 3   country_4                         73539 non-null  int64  \n 4   country_5                         73539 non-null  int64  \n 5   country_6                         73539 non-null  int64  \n 6   country_7                         73539 non-null  int64  \n 7   email_sent_weekday_0              73539 non-null  int64  \n 8   email_sent_weekday_1              73539 non-null  int64  \n 9   email_sent_weekday_2              73539 non-null  int64  \n 10  email_sent_weekday_3              73539 non-null  int64  \n 11  email_sent_weekday_4              73539 non-null  int64  \n 12  email_sent_weekday_5              73539 non-null  int64  \n 13  email_sent_weekday_6              73539 non-null  int64  \n 14  never_open                        73539 non-null  int64  \n 15  never_login                       73539 non-null  int64  \n 16  never_checkout                    73539 non-null  int64  \n 17  open_count_rate_last_10_days      73539 non-null  float64\n 18  open_count_rate_last_30_days      73539 non-null  float64\n 19  open_count_rate_last_60_days      73539 non-null  float64\n 20  login_count_rate_last_10_days     73539 non-null  float64\n 21  login_count_rate_last_30_days     73539 non-null  float64\n 22  login_count_rate_last_60_days     73539 non-null  float64\n 23  checkout_count_rate_last_10_days  73539 non-null  float64\n 24  checkout_count_rate_last_30_days  73539 non-null  float64\n 25  checkout_count_rate_last_60_days  73539 non-null  float64\n 26  open_count_further_20_days        73539 non-null  float64\n 27  checkout_count_further_20_days    73539 non-null  float64\n 28  login_count_further_30_days       73539 non-null  float64\n 29  checkout_count_further_30_days    73539 non-null  float64\n 30  open_count_further_30_days        73539 non-null  float64\n 31  last_open_day                     73539 non-null  float64\n 32  subject_line_length               73539 non-null  float64\n 33  login_count_further_20_days       73539 non-null  float64\n 34  last_checkout_day                 73539 non-null  float64\n 35  checkout_count_last_10_days       73539 non-null  float64\n 36  last_login_day                    73539 non-null  float64\n 37  open_count_last_10_days           73539 non-null  float64\n 38  login_count_last_10_days          73539 non-null  float64\n 39  age                               73539 non-null  float64\n 40  attr_3_0.0                        73539 non-null  int64  \n 41  attr_3_1.0                        73539 non-null  int64  \n 42  attr_3_2.0                        73539 non-null  int64  \n 43  attr_3_3.0                        73539 non-null  int64  \n 44  attr_3_4.0                        73539 non-null  int64  \n 45  domain_@163.com                   73539 non-null  int64  \n 46  domain_@gmail.com                 73539 non-null  int64  \n 47  domain_@hotmail.com               73539 non-null  int64  \n 48  domain_@icloud.com                73539 non-null  int64  \n 49  domain_@live.com                  73539 non-null  int64  \n 50  domain_@outlook.com               73539 non-null  int64  \n 51  domain_@qq.com                    73539 non-null  int64  \n 52  domain_@rocketmail.com            73539 non-null  int64  \n 53  domain_@yahoo.com                 73539 non-null  int64  \n 54  domain_@ymail.com                 73539 non-null  int64  \n 55  domain_other                      73539 non-null  int64  \n 56  open_flag                         73539 non-null  int64  \ndtypes: float64(23), int64(34)\nmemory usage: 32.5 MB\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(new_train_df.open_flag.value_counts())","execution_count":98,"outputs":[{"output_type":"stream","text":"0    62083\n1    11456\nName: open_flag, dtype: int64\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Divide by class\ndf_class_0 = new_train_df[new_train_df['open_flag'] == 0]\ndf_class_1 = new_train_df[new_train_df['open_flag'] == 1]\n\n# Upsampling\nclass_1_upsampling = df_class_1.sample(20000, replace=True)\nbalanced_train_df = pd.concat([df_class_0, df_class_1, class_1_upsampling], axis=0)","execution_count":99,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features = new_train_df.iloc[:, :-1]\ntrain_labels = new_train_df.iloc[:, -1]","execution_count":100,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.3. Test"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv('/kaggle/input/open-shopee-code-league-marketing-analytics/test.csv')","execution_count":101,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.info()","execution_count":102,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 55970 entries, 0 to 55969\nData columns (total 17 columns):\n #   Column                       Non-Null Count  Dtype \n---  ------                       --------------  ----- \n 0   country_code                 55970 non-null  int64 \n 1   grass_date                   55970 non-null  object\n 2   user_id                      55970 non-null  int64 \n 3   subject_line_length          55970 non-null  int64 \n 4   last_open_day                55970 non-null  object\n 5   last_login_day               55970 non-null  object\n 6   last_checkout_day            55970 non-null  object\n 7   open_count_last_10_days      55970 non-null  int64 \n 8   open_count_last_30_days      55970 non-null  int64 \n 9   open_count_last_60_days      55970 non-null  int64 \n 10  login_count_last_10_days     55970 non-null  int64 \n 11  login_count_last_30_days     55970 non-null  int64 \n 12  login_count_last_60_days     55970 non-null  int64 \n 13  checkout_count_last_10_days  55970 non-null  int64 \n 14  checkout_count_last_30_days  55970 non-null  int64 \n 15  checkout_count_last_60_days  55970 non-null  int64 \n 16  row_id                       55970 non-null  int64 \ndtypes: int64(13), object(4)\nmemory usage: 7.3+ MB\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# country\ntest_df_country = process_categorical(test_df, \"country_code\", \"country\")\n\n# convert grass_date and create email_sent_dayofweek\ntest_df['grass_date'] = pd.to_datetime(test_df['grass_date'])\ntest_df['email_sent_dayofweek'] = test_df['grass_date'].dt.dayofweek\ntest_df_weekday = process_categorical(test_df, \"email_sent_dayofweek\", \"email_sent_weekday\")\n\n# never_open, never_login, never_checkout\ntest_df['never_open'] = test_df['last_open_day'].apply(is_never)\ntest_df['never_login'] = test_df['last_login_day'].apply(is_never)\ntest_df['never_checkout'] = test_df['last_checkout_day'].apply(is_never)\n\n# replace never_open, never_login, never_checkout | last_open_day, last_login_day, last_checkout_day\ntest_df['last_open_day'] = test_df['last_open_day'].replace(['Never open'],'1600')\ntest_df['last_login_day'] = test_df['last_login_day'].replace(['Never login'],'36000')\ntest_df['last_checkout_day'] = test_df['last_checkout_day'].replace(['Never checkout'],'3000')\n\ntest_df['last_open_day'] = test_df['last_open_day'].astype('int64')\ntest_df['last_login_day'] = test_df['last_login_day'].astype('int64')\ntest_df['last_checkout_day'] = test_df['last_checkout_day'].astype('int64')\n\n# open_count_last_10_days, open_count_last_30_days, open_count_last_60_days\ntest_df['open_count_rate_last_10_days'] = test_df['open_count_last_10_days'].apply(convert_rate10)\ntest_df['open_count_rate_last_30_days'] = test_df['open_count_last_30_days'].apply(convert_rate30)\ntest_df['open_count_rate_last_60_days'] = test_df['open_count_last_60_days'].apply(convert_rate60)\n\ntest_df['open_count_further_20_days'] = test_df['open_count_last_30_days'] - test_df['open_count_last_10_days']\ntest_df['open_count_further_30_days'] = test_df['open_count_last_60_days'] - test_df['open_count_last_30_days']\n\n# login_count_last_10_days, login_count_last_30_days, login_count_last_60_days\ntest_df['login_count_rate_last_10_days'] = test_df['login_count_last_10_days'].apply(convert_rate10)\ntest_df['login_count_rate_last_30_days'] = test_df['login_count_last_30_days'].apply(convert_rate30)\ntest_df['login_count_rate_last_60_days'] = test_df['login_count_last_60_days'].apply(convert_rate60)\n\ntest_df['login_count_further_20_days'] = test_df['login_count_last_30_days'] - test_df['login_count_last_10_days']\ntest_df['login_count_further_30_days'] = test_df['login_count_last_60_days'] - test_df['login_count_last_30_days']\n\n# checkout_count_last_10_days, checkout_count_last_30_days, checkout_count_last_60_days\ntest_df['checkout_count_rate_last_10_days'] = test_df['checkout_count_last_10_days'].apply(convert_rate10)\ntest_df['checkout_count_rate_last_30_days'] = test_df['checkout_count_last_30_days'].apply(convert_rate30)\ntest_df['checkout_count_rate_last_60_days'] = test_df['checkout_count_last_60_days'].apply(convert_rate60)\n\ntest_df['checkout_count_further_20_days'] = test_df['checkout_count_last_30_days'] - test_df['checkout_count_last_10_days']\ntest_df['checkout_count_further_30_days'] = test_df['checkout_count_last_60_days'] - test_df['checkout_count_last_30_days']\n\n# row_id: drop\ntest_df = test_df.drop([\"row_id\"],axis = 1)","execution_count":103,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_num = ['subject_line_length',\n                'last_open_day', 'last_login_day', 'last_checkout_day',\n                'open_count_last_10_days',#'open_count_last_30_days','open_count_last_60_days',\n                'open_count_further_20_days','open_count_further_30_days',\n                'login_count_last_10_days',#'login_count_last_30_days','login_count_last_60_days',\n                'login_count_further_20_days','login_count_further_30_days',\n                'checkout_count_last_10_days',#'checkout_count_last_30_days','checkout_count_last_60_days',\n                'checkout_count_further_20_days','checkout_count_further_30_days',\n               ]\ndrop_numerical_columns = []\ntest_df_numerical = process_numerical_data(test_df,_num,drop_numerical_columns)","execution_count":104,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# merge with user_df\nnew_test_df = pd.concat([test_df_country, test_df_weekday,\n                         test_df[[\n                             'user_id',\n#                              'subject_line_length',\n#                              'last_open_day','last_login_day','last_checkout_day',\n                             'never_open','never_login','never_checkout',\n                             'open_count_rate_last_10_days','open_count_rate_last_30_days','open_count_rate_last_60_days',\n                             'login_count_rate_last_10_days','login_count_rate_last_30_days','login_count_rate_last_60_days',\n                             'checkout_count_rate_last_10_days','checkout_count_rate_last_30_days','checkout_count_rate_last_60_days',\n#                              'open_count_last_10_days','open_count_last_30_days','open_count_last_60_days',\n#                              'open_count_further_20_days','open_count_further_30_days',\n#                              'login_count_last_10_days','login_count_last_30_days','login_count_last_60_days',\n#                              'login_count_further_20_days','login_count_further_30_days',\n#                              'checkout_count_last_10_days','checkout_count_last_30_days','checkout_count_last_60_days',\n#                              'checkout_count_further_20_days','checkout_count_further_30_days',\n                                 ]],\n                         test_df_numerical\n                         ], axis=1)\nnew_test_df = new_test_df.merge(new_user_df, how='left', left_on='user_id', right_on='user_id')\nnew_test_df = new_test_df.drop([\"user_id\"], axis=1)","execution_count":105,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_x = new_test_df\ntest_x.info()","execution_count":106,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nInt64Index: 55970 entries, 0 to 55969\nData columns (total 56 columns):\n #   Column                            Non-Null Count  Dtype  \n---  ------                            --------------  -----  \n 0   country_1                         55970 non-null  int64  \n 1   country_2                         55970 non-null  int64  \n 2   country_3                         55970 non-null  int64  \n 3   country_4                         55970 non-null  int64  \n 4   country_5                         55970 non-null  int64  \n 5   country_6                         55970 non-null  int64  \n 6   country_7                         55970 non-null  int64  \n 7   email_sent_weekday_0              55970 non-null  int64  \n 8   email_sent_weekday_1              55970 non-null  int64  \n 9   email_sent_weekday_2              55970 non-null  int64  \n 10  email_sent_weekday_3              55970 non-null  int64  \n 11  email_sent_weekday_4              55970 non-null  int64  \n 12  email_sent_weekday_5              55970 non-null  int64  \n 13  email_sent_weekday_6              55970 non-null  int64  \n 14  never_open                        55970 non-null  int64  \n 15  never_login                       55970 non-null  int64  \n 16  never_checkout                    55970 non-null  int64  \n 17  open_count_rate_last_10_days      55970 non-null  float64\n 18  open_count_rate_last_30_days      55970 non-null  float64\n 19  open_count_rate_last_60_days      55970 non-null  float64\n 20  login_count_rate_last_10_days     55970 non-null  float64\n 21  login_count_rate_last_30_days     55970 non-null  float64\n 22  login_count_rate_last_60_days     55970 non-null  float64\n 23  checkout_count_rate_last_10_days  55970 non-null  float64\n 24  checkout_count_rate_last_30_days  55970 non-null  float64\n 25  checkout_count_rate_last_60_days  55970 non-null  float64\n 26  open_count_further_20_days        55970 non-null  float64\n 27  checkout_count_further_20_days    55970 non-null  float64\n 28  login_count_further_30_days       55970 non-null  float64\n 29  checkout_count_further_30_days    55970 non-null  float64\n 30  open_count_further_30_days        55970 non-null  float64\n 31  last_open_day                     55970 non-null  float64\n 32  subject_line_length               55970 non-null  float64\n 33  login_count_further_20_days       55970 non-null  float64\n 34  last_checkout_day                 55970 non-null  float64\n 35  checkout_count_last_10_days       55970 non-null  float64\n 36  last_login_day                    55970 non-null  float64\n 37  open_count_last_10_days           55970 non-null  float64\n 38  login_count_last_10_days          55970 non-null  float64\n 39  age                               55970 non-null  float64\n 40  attr_3_0.0                        55970 non-null  int64  \n 41  attr_3_1.0                        55970 non-null  int64  \n 42  attr_3_2.0                        55970 non-null  int64  \n 43  attr_3_3.0                        55970 non-null  int64  \n 44  attr_3_4.0                        55970 non-null  int64  \n 45  domain_@163.com                   55970 non-null  int64  \n 46  domain_@gmail.com                 55970 non-null  int64  \n 47  domain_@hotmail.com               55970 non-null  int64  \n 48  domain_@icloud.com                55970 non-null  int64  \n 49  domain_@live.com                  55970 non-null  int64  \n 50  domain_@outlook.com               55970 non-null  int64  \n 51  domain_@qq.com                    55970 non-null  int64  \n 52  domain_@rocketmail.com            55970 non-null  int64  \n 53  domain_@yahoo.com                 55970 non-null  int64  \n 54  domain_@ymail.com                 55970 non-null  int64  \n 55  domain_other                      55970 non-null  int64  \ndtypes: float64(23), int64(33)\nmemory usage: 24.3 MB\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# 2. Confirmation\n* Check all input feature for training and testing dataset\n* Split train - validation set"},{"metadata":{"trusted":true},"cell_type":"code","source":"# split the data into train and validation set\ntrain_x, valid_x, train_y, valid_y = train_test_split(train_features,train_labels,test_size=0.2,random_state=27,shuffle=True)\n\n# cross-validation using kfold\n# kf = KFold(n_splits=10)","execution_count":108,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Apply PCA"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\npca = PCA(n_components=25)\ntrain_x_pca = pd.DataFrame(pca.fit_transform(train_x))\nvalid_x_pca = pd.DataFrame(pca.transform(valid_x))\ntest_x_pca = pd.DataFrame(pca.transform(test_x))","execution_count":109,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Modelling"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Random Forest\nrf_clf = RandomForestClassifier(max_features='auto', max_depth=20, random_state=27)\nrf_clf.fit(train_x_pca, train_y)\n\ny_true, y_pred = valid_y , rf_clf.predict(valid_x_pca)\nmatthews_score = evaluate_model(rf_clf, valid_x_pca, valid_y, metric=matthews_corrcoef)\nprint('Results on the test set:')\nprint(f'MCC Score = {matthews_score}')\nprint(classification_report(y_true, y_pred))","execution_count":112,"outputs":[{"output_type":"stream","text":"Results on the test set:\nMCC Score = 0.49795656689008744\n              precision    recall  f1-score   support\n\n           0       0.90      0.97      0.93     12449\n           1       0.70      0.44      0.54      2259\n\n    accuracy                           0.89     14708\n   macro avg       0.80      0.70      0.74     14708\nweighted avg       0.87      0.89      0.87     14708\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Random Forest\nrf_clf2 = RandomForestClassifier(max_features='auto', max_depth=25, random_state=27)\nrf_clf2.fit(train_x, train_y)\n\ny_true, y_pred = valid_y , rf_clf2.predict(valid_x)\nmatthews_score = evaluate_model(rf_clf2, valid_x, valid_y, metric=matthews_corrcoef)\nprint('Results on the test set:')\nprint(f'MCC Score = {matthews_score}')\nprint(classification_report(y_true, y_pred))","execution_count":111,"outputs":[{"output_type":"stream","text":"Results on the test set:\nMCC Score = 0.5168542194824178\n              precision    recall  f1-score   support\n\n           0       0.91      0.97      0.94     12449\n           1       0.72      0.46      0.56      2259\n\n    accuracy                           0.89     14708\n   macro avg       0.82      0.71      0.75     14708\nweighted avg       0.88      0.89      0.88     14708\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# XGBoost\nimport xgboost as xgb\nxgb_model1 = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42)\nxgb_model1.fit(train_x, train_y)#, early_stopping_rounds=5, eval_set=[(test_x, test_y)])\n\ny_true, y_pred = valid_y , xgb_model1.predict(valid_x)\nmatthews_score = evaluate_model(xgb_model1, valid_x, valid_y, metric=matthews_corrcoef)\nprint('Results on the test set:')\nprint(f'MCC Score = {matthews_score}')\nprint(classification_report(y_true, y_pred))","execution_count":113,"outputs":[{"output_type":"stream","text":"Results on the test set:\nMCC Score = 0.514058784352614\n              precision    recall  f1-score   support\n\n           0       0.91      0.96      0.94     12449\n           1       0.70      0.47      0.56      2259\n\n    accuracy                           0.89     14708\n   macro avg       0.80      0.72      0.75     14708\nweighted avg       0.88      0.89      0.88     14708\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# 4. Add prediction as new column"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x_pca['predicted'] = rf_clf.predict(train_x_pca)\nvalid_x_pca['predicted'] = rf_clf.predict(valid_x_pca)\ntest_x_pca['predicted'] = rf_clf.predict(test_x_pca)","execution_count":74,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x['predicted'] = rf_clf2.predict(train_x)\nvalid_x['predicted'] = rf_clf2.predict(valid_x)\ntest_x['predicted'] = rf_clf2.predict(test_x)","execution_count":115,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \"\"\"Entry point for launching an IPython kernel.\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n","name":"stderr"}]},{"metadata":{},"cell_type":"markdown","source":"# 5. Modelling 2"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# Bagging\nbg_clf = BaggingClassifier(base_estimator=SVC(), n_estimators=20, random_state=10, max_features=10)\nbg_clf.fit(train_x, train_y)\n\ny_true, y_pred = test_y , bg_clf.predict(test_x)\nmatthews_score = evaluate_model(bg_clf, test_x, test_y, metric=matthews_corrcoef)\nprint('Results on the test set:')\nprint(f'MCC Score = {matthews_score}')\nprint(classification_report(y_true, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# AdaBoost\nad_clf = AdaBoostClassifier(\n    base_estimator=RandomForestClassifier(max_features='auto', max_depth=25, random_state=10), \n    n_estimators=50, \n    random_state=10, \n    learning_rate=0.1\n)\nad_clf.fit(train_x, train_y)\n\ny_true, y_pred = test_y , ad_clf.predict(test_x)\nmatthews_score = evaluate_model(ad_clf, test_x, test_y, metric=matthews_corrcoef)\nprint('Results on the test set:')\nprint(f'MCC Score = {matthews_score}')\nprint(classification_report(y_true, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# MLP\ninput_size = train_x.shape[1]\nNN_sgd = MLPClassifier(\n    hidden_layer_sizes=(256, 512, 256,),\n    solver='sgd',\n    learning_rate='adaptive',\n    momentum=0.8,\n    max_iter=1000, \n    shuffle=True, \n    random_state=27,\n    early_stopping=True,\n    verbose=True)\nNN_sgd.fit(train_x_pca,train_y)\n\ny_true, y_pred = test_y , NN_sgd.predict(valid_x_pca)\nmatthews_score = evaluate_model(NN_sgd, valid_x_pca, valid_y, metric=matthews_corrcoef)\nprint('Results on the test set:')\nprint(f'MCC Score = {matthews_score}')\nprint(classification_report(y_true, y_pred))","execution_count":82,"outputs":[{"output_type":"stream","text":"Iteration 1, loss = 0.43221590\nValidation score: 0.853501\nIteration 2, loss = 0.34700339\nValidation score: 0.886642\nIteration 3, loss = 0.29780979\nValidation score: 0.896669\nIteration 4, loss = 0.26358889\nValidation score: 0.904827\nIteration 5, loss = 0.23320742\nValidation score: 0.915194\nIteration 6, loss = 0.20165501\nValidation score: 0.930659\nIteration 7, loss = 0.16948258\nValidation score: 0.953093\nIteration 8, loss = 0.13851559\nValidation score: 0.966859\nIteration 9, loss = 0.11190216\nValidation score: 0.981985\nIteration 10, loss = 0.09193430\nValidation score: 0.989803\nIteration 11, loss = 0.07837688\nValidation score: 0.991672\nIteration 12, loss = 0.06955971\nValidation score: 0.991842\nIteration 13, loss = 0.06366150\nValidation score: 0.991842\nIteration 14, loss = 0.05973683\nValidation score: 0.992012\nIteration 15, loss = 0.05679630\nValidation score: 0.992012\nIteration 16, loss = 0.05482305\nValidation score: 0.992012\nIteration 17, loss = 0.05327670\nValidation score: 0.992012\nIteration 18, loss = 0.05208190\nValidation score: 0.992182\nIteration 19, loss = 0.05112463\nValidation score: 0.992182\nIteration 20, loss = 0.05026202\nValidation score: 0.992182\nIteration 21, loss = 0.04953045\nValidation score: 0.992182\nIteration 22, loss = 0.04911576\nValidation score: 0.992182\nIteration 23, loss = 0.04852714\nValidation score: 0.992182\nIteration 24, loss = 0.04810751\nValidation score: 0.992182\nIteration 25, loss = 0.04765560\nValidation score: 0.992182\nIteration 26, loss = 0.04741937\nValidation score: 0.992182\nIteration 27, loss = 0.04695888\nValidation score: 0.992182\nIteration 28, loss = 0.04675145\nValidation score: 0.992182\nIteration 29, loss = 0.04656458\nValidation score: 0.992182\nValidation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000200\nIteration 30, loss = 0.04608645\nValidation score: 0.992182\nIteration 31, loss = 0.04598065\nValidation score: 0.992182\nIteration 32, loss = 0.04598022\nValidation score: 0.992182\nIteration 33, loss = 0.04586258\nValidation score: 0.992182\nIteration 34, loss = 0.04585585\nValidation score: 0.992182\nIteration 35, loss = 0.04581157\nValidation score: 0.992182\nIteration 36, loss = 0.04570810\nValidation score: 0.992182\nIteration 37, loss = 0.04571571\nValidation score: 0.992182\nIteration 38, loss = 0.04566591\nValidation score: 0.992182\nIteration 39, loss = 0.04562421\nValidation score: 0.992182\nIteration 40, loss = 0.04561549\nValidation score: 0.992182\nValidation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000040\nIteration 41, loss = 0.04546047\nValidation score: 0.992182\nIteration 42, loss = 0.04546008\nValidation score: 0.992182\nIteration 43, loss = 0.04544254\nValidation score: 0.992182\nIteration 44, loss = 0.04545049\nValidation score: 0.992182\nIteration 45, loss = 0.04542745\nValidation score: 0.992182\nIteration 46, loss = 0.04543609\nValidation score: 0.992182\nIteration 47, loss = 0.04542168\nValidation score: 0.992182\nIteration 48, loss = 0.04540777\nValidation score: 0.992182\nIteration 49, loss = 0.04540496\nValidation score: 0.992182\nIteration 50, loss = 0.04539719\nValidation score: 0.992182\nIteration 51, loss = 0.04538478\nValidation score: 0.992182\nValidation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000008\nIteration 52, loss = 0.04536378\nValidation score: 0.992182\nIteration 53, loss = 0.04535841\nValidation score: 0.992182\nIteration 54, loss = 0.04535439\nValidation score: 0.992182\nIteration 55, loss = 0.04535159\nValidation score: 0.992182\nIteration 56, loss = 0.04534911\nValidation score: 0.992182\nIteration 57, loss = 0.04534839\nValidation score: 0.992182\nIteration 58, loss = 0.04534702\nValidation score: 0.992182\nIteration 59, loss = 0.04534619\nValidation score: 0.992182\nIteration 60, loss = 0.04534429\nValidation score: 0.992182\nIteration 61, loss = 0.04534315\nValidation score: 0.992182\nIteration 62, loss = 0.04534069\nValidation score: 0.992182\nValidation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000002\nIteration 63, loss = 0.04533463\nValidation score: 0.992182\nIteration 64, loss = 0.04533404\nValidation score: 0.992182\nIteration 65, loss = 0.04533368\nValidation score: 0.992182\nIteration 66, loss = 0.04533319\nValidation score: 0.992182\nIteration 67, loss = 0.04533304\nValidation score: 0.992182\nIteration 68, loss = 0.04533291\nValidation score: 0.992182\nIteration 69, loss = 0.04533237\nValidation score: 0.992182\nIteration 70, loss = 0.04533238\nValidation score: 0.992182\nIteration 71, loss = 0.04533176\nValidation score: 0.992182\nIteration 72, loss = 0.04533153\nValidation score: 0.992182\nIteration 73, loss = 0.04533137\nValidation score: 0.992182\nValidation score did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000000\nIteration 74, loss = 0.04532978\nValidation score: 0.992182\nIteration 75, loss = 0.04532965\nValidation score: 0.992182\nIteration 76, loss = 0.04532959\nValidation score: 0.992182\nIteration 77, loss = 0.04532956\nValidation score: 0.992182\nIteration 78, loss = 0.04532947\nValidation score: 0.992182\nIteration 79, loss = 0.04532946\nValidation score: 0.992182\nIteration 80, loss = 0.04532944\nValidation score: 0.992182\nIteration 81, loss = 0.04532936\nValidation score: 0.992182\nIteration 82, loss = 0.04532923\nValidation score: 0.992182\nIteration 83, loss = 0.04532919\nValidation score: 0.992182\nIteration 84, loss = 0.04532920\nValidation score: 0.992182\nValidation score did not improve more than tol=0.000100 for 10 consecutive epochs. Learning rate too small. Stopping.\nResults on the test set:\nMCC Score = 0.5040949991584631\n              precision    recall  f1-score   support\n\n           0       0.91      0.97      0.94     12449\n           1       0.71      0.45      0.55      2259\n\n    accuracy                           0.89     14708\n   macro avg       0.81      0.71      0.74     14708\nweighted avg       0.88      0.89      0.88     14708\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# MLP adam\ninput_size = train_x.shape[1]\nNN_adam = MLPClassifier(\n    hidden_layer_sizes=(256, 512, 256,),\n    solver='adam',\n    learning_rate='adaptive',\n    learning_rate_init=0.01,\n    max_iter=1000, \n    shuffle=True, \n    random_state=27,\n    early_stopping=True,\n    verbose=True)\nNN_adam.fit(train_x_pca,train_y)\n\ny_true, y_pred = test_y , NN_adam.predict(valid_x_pca)\nmatthews_score = evaluate_model(NN_adam, valid_x_pca, valid_y, metric=matthews_corrcoef)\nprint('Results on the test set:')\nprint(f'MCC Score = {matthews_score}')\nprint(classification_report(y_true, y_pred))","execution_count":81,"outputs":[{"output_type":"stream","text":"Iteration 1, loss = 0.10649851\nValidation score: 0.990313\nIteration 2, loss = 0.04987715\nValidation score: 0.992182\nIteration 3, loss = 0.04639496\nValidation score: 0.991162\nIteration 4, loss = 0.04427040\nValidation score: 0.992182\nIteration 5, loss = 0.04475644\nValidation score: 0.992182\nIteration 6, loss = 0.04341453\nValidation score: 0.992182\nIteration 7, loss = 0.04791464\nValidation score: 0.990653\nIteration 8, loss = 0.04438403\nValidation score: 0.992182\nIteration 9, loss = 0.04249351\nValidation score: 0.988103\nIteration 10, loss = 0.04773133\nValidation score: 0.990653\nIteration 11, loss = 0.05160993\nValidation score: 0.989633\nIteration 12, loss = 0.04653751\nValidation score: 0.990993\nIteration 13, loss = 0.04600788\nValidation score: 0.990993\nValidation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\nResults on the test set:\nMCC Score = 0.5040949991584631\n              precision    recall  f1-score   support\n\n           0       0.91      0.97      0.94     12449\n           1       0.71      0.45      0.55      2259\n\n    accuracy                           0.89     14708\n   macro avg       0.81      0.71      0.74     14708\nweighted avg       0.88      0.89      0.88     14708\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# XGBoost\nimport xgboost as xgb\nxgb_model2 = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42)\nxgb_model2.fit(train_x, train_y)#, early_stopping_rounds=5, eval_set=[(test_x, test_y)])\n\ny_true, y_pred = valid_y , xgb_model2.predict(valid_x)\nmatthews_score = evaluate_model(xgb_model2, valid_x, valid_y, metric=matthews_corrcoef)\nprint('Results on the test set:')\nprint(f'MCC Score = {matthews_score}')\nprint(classification_report(y_true, y_pred))","execution_count":119,"outputs":[{"output_type":"stream","text":"Results on the test set:\nMCC Score = 0.5165938924054588\n              precision    recall  f1-score   support\n\n           0       0.91      0.97      0.94     12449\n           1       0.72      0.46      0.56      2259\n\n    accuracy                           0.89     14708\n   macro avg       0.82      0.71      0.75     14708\nweighted avg       0.88      0.89      0.88     14708\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Random Forest\nrf_clf3 = RandomForestClassifier(max_features='auto', max_depth=None, random_state=27)\nrf_clf3.fit(train_x, train_y)\n\ny_true, y_pred = valid_y , rf_clf3.predict(valid_x)\nmatthews_score = evaluate_model(rf_clf3, valid_x, valid_y, metric=matthews_corrcoef)\nprint('Results on the test set:')\nprint(f'MCC Score = {matthews_score}')\nprint(classification_report(y_true, y_pred))","execution_count":120,"outputs":[{"output_type":"stream","text":"Results on the test set:\nMCC Score = 0.5165938924054588\n              precision    recall  f1-score   support\n\n           0       0.91      0.97      0.94     12449\n           1       0.72      0.46      0.56      2259\n\n    accuracy                           0.89     14708\n   macro avg       0.82      0.71      0.75     14708\nweighted avg       0.88      0.89      0.88     14708\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# 6. Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Random forest\ntest_y_pred = xgb_model2.predict(test_x)\ndf_result = pd.DataFrame.from_dict(dict({'row_id':list(sample_submission_df['row_id']),\n                                         'open_flag':test_y_pred}))\ndf_result","execution_count":122,"outputs":[{"output_type":"execute_result","execution_count":122,"data":{"text/plain":"       row_id  open_flag\n0           0          0\n1           1          0\n2           2          0\n3           3          0\n4           4          0\n...       ...        ...\n55965   55965          0\n55966   55966          0\n55967   55967          0\n55968   55968          0\n55969   55969          1\n\n[55970 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>row_id</th>\n      <th>open_flag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>55965</th>\n      <td>55965</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>55966</th>\n      <td>55966</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>55967</th>\n      <td>55967</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>55968</th>\n      <td>55968</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>55969</th>\n      <td>55969</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>55970 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_result['open_flag'].value_counts()","execution_count":123,"outputs":[{"output_type":"execute_result","execution_count":123,"data":{"text/plain":"0    51048\n1     4922\nName: open_flag, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_result.to_csv('submission_xgb_model2.csv', index=False)","execution_count":124,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}