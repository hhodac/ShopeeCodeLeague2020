{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":22,"outputs":[{"output_type":"stream","text":"/kaggle/input/shopee-sentiment-analysis/train.csv\n/kaggle/input/shopee-sentiment-analysis/sampleSubmission.csv\n/kaggle/input/shopee-sentiment-analysis/test.csv\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# 1. Load data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\npath = '/kaggle/input/shopee-sentiment-analysis/'\ntrain_df = pd.read_csv('/kaggle/input/shopee-sentiment-analysis/train.csv')\ntest_df = pd.read_csv('/kaggle/input/shopee-sentiment-analysis/test.csv')\nsampleSubmission_df = pd.read_csv('/kaggle/input/shopee-sentiment-analysis/sampleSubmission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sampleSubmission_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(sampleSubmission_df.rating[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from fastai.text import *\nbs=8\ndata_clas = (TextList.from_csv(path, csv_name='train.csv', cols='review')\n        .split_by_rand_pct()\n        .label_from_df(cols='rating')\n        .add_test(TextList.from_csv(path, csv_name='test.csv', cols='review'))\n        .databunch(bs=bs))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = text_classifier_learner(data_clas, Transformer, drop_mult=0.3, model_dir='/kaggle/output')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.lr_find()","execution_count":46,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n                background: #F44336;\n            }\n        </style>\n      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      0.00% [0/1 00:00<00:00]\n    </div>\n    \n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>accuracy</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>\n\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n                background: #F44336;\n            }\n        </style>\n      <progress value='94' class='' max='14681' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      0.64% [94/14681 00:09<25:22 4.6873]\n    </div>\n    "},"metadata":{}},{"output_type":"stream","text":"LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.recorder.plot()","execution_count":47,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{},"cell_type":"markdown","source":"# 3. Train model"},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.unfreeze()","execution_count":53,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(1, 1e-3, moms=(0.8,0.7))","execution_count":54,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n                background: #F44336;\n            }\n        </style>\n      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      0.00% [0/1 00:00<00:00]\n    </div>\n    \n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>accuracy</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>\n\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n                background: #F44336;\n            }\n        </style>\n      <progress value='116' class='' max='14681' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      0.79% [116/14681 00:12<26:00 1.3252]\n    </div>\n    "},"metadata":{}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-54-d623ca96b285>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmoms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/train.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, final_div, wd, callbacks, tot_epochs, start_epoch)\u001b[0m\n\u001b[1;32m     21\u001b[0m     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor, pct_start=pct_start,\n\u001b[1;32m     22\u001b[0m                                        final_div=final_div, tot_epochs=tot_epochs, start_epoch=start_epoch))\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m def fit_fc(learn:Learner, tot_epochs:int=1, lr:float=defaults.lr,  moms:Tuple[float,float]=(0.95,0.85), start_pct:float=0.72,\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callback_fns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mskip_bwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mskip_bwd\u001b[0m\u001b[0;34m:\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.save('first')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.load('first')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.freeze_to(-2)","execution_count":45,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(1, slice(1e-5/(2.6**4), 1e-4), moms=(0.8,0.7))","execution_count":48,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>accuracy</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1.170853</td>\n      <td>1.133911</td>\n      <td>0.464308</td>\n      <td>12:00</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.save('second')","execution_count":49,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.load('second')","execution_count":50,"outputs":[{"output_type":"execute_result","execution_count":50,"data":{"text/plain":"RNNLearner(data=TextClasDataBunch;\n\nTrain: LabelList (117449 items)\nx: TextList\nxxbos xxmaj ga disappointed neat products .. xxmaj xxunk xxmaj xxunk xxmaj speed ​​of delivery is good .,xxbos xxmaj xxunk replace broken glass , broken chargernya,xxbos xxmaj nyesel bngt dsni shopping antecedent photo message pictures gk according xxunk existing collagen super fit nyampe xxunk my house open ehhh collagen contents even in the face pdahal jg description super existing collagen xxunk writing my check lg in photo captions already ma xxmaj the change ma pictures that the face .,xxbos xxmaj hours not a hologram,xxbos xxmaj well , according to xxmaj price\ny: CategoryList\n1,1,1,1,1\nPath: /kaggle/input/shopee-sentiment-analysis;\n\nValid: LabelList (29362 items)\nx: TextList\nxxbos xxmaj goods made up a nice red color .. sorry .. but indeterminate as expectations turned out to be snugly fitted jd her look thick hp .. xxmaj tp passable deh make ganti2 case .. xxmaj thanks yaa ..,xxbos xxmaj kirain given turned out to use bubble wrap cardboard hehehhe aja kok 👍 gapapa still good thanks,xxbos xxmaj fast , friendly and top bgt dkasi sample ... xxmaj makasi it 's gone until ya and by order,xxbos beautiful xxrep 7 👍,xxbos xxmaj for the umpteenth time his thanks a lot kaka xxrep 40 .\ny: CategoryList\n3,3,4,5,4\nPath: /kaggle/input/shopee-sentiment-analysis;\n\nTest: LabelList (60427 items)\nx: TextList\nxxbos xxmaj great danger , cool , motif and cantik2 jg models . xxmaj delivery cepet . xxmaj tp packing less okay krn only wear clear plastic nerawang xxunk contents jd,xxbos xxmaj one of the shades do n't fit well,xxbos xxmaj very comfortable,xxbos xxmaj fast delivery . xxmaj product expiry is on xxmaj dec 2022 . xxmaj product wrap properly . xxmaj no damage on the item .,xxbos it 's s xxrep 5 o cute ! i like playing with the glitters better than xxunk on my phone now . item was also xxunk earlier than i expected . thank you seller ! may you have more buyers to come . 😊 😊 😊\ny: EmptyLabelList\n,,,,\nPath: /kaggle/input/shopee-sentiment-analysis, model=SequentialRNN(\n  (0): MultiBatchEncoder(\n    (module): Transformer(\n      (encoder): Embedding(15168, 768)\n      (pos_enc): Embedding(512, 768)\n      (drop_emb): Dropout(p=0.03, inplace=False)\n      (layers): ModuleList(\n        (0): DecoderLayer(\n          (mhra): MultiHeadAttention(\n            (attention): Linear(in_features=768, out_features=2304, bias=True)\n            (out): Linear(in_features=768, out_features=768, bias=True)\n            (drop_att): Dropout(p=0.03, inplace=False)\n            (drop_res): Dropout(p=0.03, inplace=False)\n            (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (ff): SequentialEx(\n            (layers): ModuleList(\n              (0): Linear(in_features=768, out_features=3072, bias=True)\n              (1): GeLU()\n              (2): Linear(in_features=3072, out_features=768, bias=True)\n              (3): Dropout(p=0.03, inplace=False)\n              (4): MergeLayer()\n              (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            )\n          )\n        )\n        (1): DecoderLayer(\n          (mhra): MultiHeadAttention(\n            (attention): Linear(in_features=768, out_features=2304, bias=True)\n            (out): Linear(in_features=768, out_features=768, bias=True)\n            (drop_att): Dropout(p=0.03, inplace=False)\n            (drop_res): Dropout(p=0.03, inplace=False)\n            (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (ff): SequentialEx(\n            (layers): ModuleList(\n              (0): Linear(in_features=768, out_features=3072, bias=True)\n              (1): GeLU()\n              (2): Linear(in_features=3072, out_features=768, bias=True)\n              (3): Dropout(p=0.03, inplace=False)\n              (4): MergeLayer()\n              (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            )\n          )\n        )\n        (2): DecoderLayer(\n          (mhra): MultiHeadAttention(\n            (attention): Linear(in_features=768, out_features=2304, bias=True)\n            (out): Linear(in_features=768, out_features=768, bias=True)\n            (drop_att): Dropout(p=0.03, inplace=False)\n            (drop_res): Dropout(p=0.03, inplace=False)\n            (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (ff): SequentialEx(\n            (layers): ModuleList(\n              (0): Linear(in_features=768, out_features=3072, bias=True)\n              (1): GeLU()\n              (2): Linear(in_features=3072, out_features=768, bias=True)\n              (3): Dropout(p=0.03, inplace=False)\n              (4): MergeLayer()\n              (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            )\n          )\n        )\n        (3): DecoderLayer(\n          (mhra): MultiHeadAttention(\n            (attention): Linear(in_features=768, out_features=2304, bias=True)\n            (out): Linear(in_features=768, out_features=768, bias=True)\n            (drop_att): Dropout(p=0.03, inplace=False)\n            (drop_res): Dropout(p=0.03, inplace=False)\n            (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (ff): SequentialEx(\n            (layers): ModuleList(\n              (0): Linear(in_features=768, out_features=3072, bias=True)\n              (1): GeLU()\n              (2): Linear(in_features=3072, out_features=768, bias=True)\n              (3): Dropout(p=0.03, inplace=False)\n              (4): MergeLayer()\n              (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            )\n          )\n        )\n        (4): DecoderLayer(\n          (mhra): MultiHeadAttention(\n            (attention): Linear(in_features=768, out_features=2304, bias=True)\n            (out): Linear(in_features=768, out_features=768, bias=True)\n            (drop_att): Dropout(p=0.03, inplace=False)\n            (drop_res): Dropout(p=0.03, inplace=False)\n            (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (ff): SequentialEx(\n            (layers): ModuleList(\n              (0): Linear(in_features=768, out_features=3072, bias=True)\n              (1): GeLU()\n              (2): Linear(in_features=3072, out_features=768, bias=True)\n              (3): Dropout(p=0.03, inplace=False)\n              (4): MergeLayer()\n              (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            )\n          )\n        )\n        (5): DecoderLayer(\n          (mhra): MultiHeadAttention(\n            (attention): Linear(in_features=768, out_features=2304, bias=True)\n            (out): Linear(in_features=768, out_features=768, bias=True)\n            (drop_att): Dropout(p=0.03, inplace=False)\n            (drop_res): Dropout(p=0.03, inplace=False)\n            (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (ff): SequentialEx(\n            (layers): ModuleList(\n              (0): Linear(in_features=768, out_features=3072, bias=True)\n              (1): GeLU()\n              (2): Linear(in_features=3072, out_features=768, bias=True)\n              (3): Dropout(p=0.03, inplace=False)\n              (4): MergeLayer()\n              (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            )\n          )\n        )\n        (6): DecoderLayer(\n          (mhra): MultiHeadAttention(\n            (attention): Linear(in_features=768, out_features=2304, bias=True)\n            (out): Linear(in_features=768, out_features=768, bias=True)\n            (drop_att): Dropout(p=0.03, inplace=False)\n            (drop_res): Dropout(p=0.03, inplace=False)\n            (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (ff): SequentialEx(\n            (layers): ModuleList(\n              (0): Linear(in_features=768, out_features=3072, bias=True)\n              (1): GeLU()\n              (2): Linear(in_features=3072, out_features=768, bias=True)\n              (3): Dropout(p=0.03, inplace=False)\n              (4): MergeLayer()\n              (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            )\n          )\n        )\n        (7): DecoderLayer(\n          (mhra): MultiHeadAttention(\n            (attention): Linear(in_features=768, out_features=2304, bias=True)\n            (out): Linear(in_features=768, out_features=768, bias=True)\n            (drop_att): Dropout(p=0.03, inplace=False)\n            (drop_res): Dropout(p=0.03, inplace=False)\n            (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (ff): SequentialEx(\n            (layers): ModuleList(\n              (0): Linear(in_features=768, out_features=3072, bias=True)\n              (1): GeLU()\n              (2): Linear(in_features=3072, out_features=768, bias=True)\n              (3): Dropout(p=0.03, inplace=False)\n              (4): MergeLayer()\n              (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            )\n          )\n        )\n        (8): DecoderLayer(\n          (mhra): MultiHeadAttention(\n            (attention): Linear(in_features=768, out_features=2304, bias=True)\n            (out): Linear(in_features=768, out_features=768, bias=True)\n            (drop_att): Dropout(p=0.03, inplace=False)\n            (drop_res): Dropout(p=0.03, inplace=False)\n            (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (ff): SequentialEx(\n            (layers): ModuleList(\n              (0): Linear(in_features=768, out_features=3072, bias=True)\n              (1): GeLU()\n              (2): Linear(in_features=3072, out_features=768, bias=True)\n              (3): Dropout(p=0.03, inplace=False)\n              (4): MergeLayer()\n              (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            )\n          )\n        )\n        (9): DecoderLayer(\n          (mhra): MultiHeadAttention(\n            (attention): Linear(in_features=768, out_features=2304, bias=True)\n            (out): Linear(in_features=768, out_features=768, bias=True)\n            (drop_att): Dropout(p=0.03, inplace=False)\n            (drop_res): Dropout(p=0.03, inplace=False)\n            (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (ff): SequentialEx(\n            (layers): ModuleList(\n              (0): Linear(in_features=768, out_features=3072, bias=True)\n              (1): GeLU()\n              (2): Linear(in_features=3072, out_features=768, bias=True)\n              (3): Dropout(p=0.03, inplace=False)\n              (4): MergeLayer()\n              (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            )\n          )\n        )\n        (10): DecoderLayer(\n          (mhra): MultiHeadAttention(\n            (attention): Linear(in_features=768, out_features=2304, bias=True)\n            (out): Linear(in_features=768, out_features=768, bias=True)\n            (drop_att): Dropout(p=0.03, inplace=False)\n            (drop_res): Dropout(p=0.03, inplace=False)\n            (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (ff): SequentialEx(\n            (layers): ModuleList(\n              (0): Linear(in_features=768, out_features=3072, bias=True)\n              (1): GeLU()\n              (2): Linear(in_features=3072, out_features=768, bias=True)\n              (3): Dropout(p=0.03, inplace=False)\n              (4): MergeLayer()\n              (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            )\n          )\n        )\n        (11): DecoderLayer(\n          (mhra): MultiHeadAttention(\n            (attention): Linear(in_features=768, out_features=2304, bias=True)\n            (out): Linear(in_features=768, out_features=768, bias=True)\n            (drop_att): Dropout(p=0.03, inplace=False)\n            (drop_res): Dropout(p=0.03, inplace=False)\n            (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (ff): SequentialEx(\n            (layers): ModuleList(\n              (0): Linear(in_features=768, out_features=3072, bias=True)\n              (1): GeLU()\n              (2): Linear(in_features=3072, out_features=768, bias=True)\n              (3): Dropout(p=0.03, inplace=False)\n              (4): MergeLayer()\n              (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            )\n          )\n        )\n      )\n    )\n  )\n  (1): PoolingLinearClassifier(\n    (layers): Sequential(\n      (0): BatchNorm1d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (1): Linear(in_features=2304, out_features=50, bias=True)\n      (2): ReLU(inplace=True)\n      (3): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (4): Dropout(p=0.1, inplace=False)\n      (5): Linear(in_features=50, out_features=5, bias=True)\n    )\n  )\n), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fa40b624440>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/kaggle/input/shopee-sentiment-analysis'), model_dir='/kaggle/output', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\nlearn: ...\nalpha: 2.0\nbeta: 1.0], layer_groups=[Sequential(\n  (0): Embedding(15168, 768)\n), Sequential(\n  (0): DecoderLayer(\n    (mhra): MultiHeadAttention(\n      (attention): Linear(in_features=768, out_features=2304, bias=True)\n      (out): Linear(in_features=768, out_features=768, bias=True)\n      (drop_att): Dropout(p=0.03, inplace=False)\n      (drop_res): Dropout(p=0.03, inplace=False)\n      (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    )\n    (ff): SequentialEx(\n      (layers): ModuleList(\n        (0): Linear(in_features=768, out_features=3072, bias=True)\n        (1): GeLU()\n        (2): Linear(in_features=3072, out_features=768, bias=True)\n        (3): Dropout(p=0.03, inplace=False)\n        (4): MergeLayer()\n        (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n  )\n  (1): DecoderLayer(\n    (mhra): MultiHeadAttention(\n      (attention): Linear(in_features=768, out_features=2304, bias=True)\n      (out): Linear(in_features=768, out_features=768, bias=True)\n      (drop_att): Dropout(p=0.03, inplace=False)\n      (drop_res): Dropout(p=0.03, inplace=False)\n      (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    )\n    (ff): SequentialEx(\n      (layers): ModuleList(\n        (0): Linear(in_features=768, out_features=3072, bias=True)\n        (1): GeLU()\n        (2): Linear(in_features=3072, out_features=768, bias=True)\n        (3): Dropout(p=0.03, inplace=False)\n        (4): MergeLayer()\n        (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n  )\n  (2): DecoderLayer(\n    (mhra): MultiHeadAttention(\n      (attention): Linear(in_features=768, out_features=2304, bias=True)\n      (out): Linear(in_features=768, out_features=768, bias=True)\n      (drop_att): Dropout(p=0.03, inplace=False)\n      (drop_res): Dropout(p=0.03, inplace=False)\n      (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    )\n    (ff): SequentialEx(\n      (layers): ModuleList(\n        (0): Linear(in_features=768, out_features=3072, bias=True)\n        (1): GeLU()\n        (2): Linear(in_features=3072, out_features=768, bias=True)\n        (3): Dropout(p=0.03, inplace=False)\n        (4): MergeLayer()\n        (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n  )\n  (3): DecoderLayer(\n    (mhra): MultiHeadAttention(\n      (attention): Linear(in_features=768, out_features=2304, bias=True)\n      (out): Linear(in_features=768, out_features=768, bias=True)\n      (drop_att): Dropout(p=0.03, inplace=False)\n      (drop_res): Dropout(p=0.03, inplace=False)\n      (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    )\n    (ff): SequentialEx(\n      (layers): ModuleList(\n        (0): Linear(in_features=768, out_features=3072, bias=True)\n        (1): GeLU()\n        (2): Linear(in_features=3072, out_features=768, bias=True)\n        (3): Dropout(p=0.03, inplace=False)\n        (4): MergeLayer()\n        (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n  )\n), Sequential(\n  (0): DecoderLayer(\n    (mhra): MultiHeadAttention(\n      (attention): Linear(in_features=768, out_features=2304, bias=True)\n      (out): Linear(in_features=768, out_features=768, bias=True)\n      (drop_att): Dropout(p=0.03, inplace=False)\n      (drop_res): Dropout(p=0.03, inplace=False)\n      (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    )\n    (ff): SequentialEx(\n      (layers): ModuleList(\n        (0): Linear(in_features=768, out_features=3072, bias=True)\n        (1): GeLU()\n        (2): Linear(in_features=3072, out_features=768, bias=True)\n        (3): Dropout(p=0.03, inplace=False)\n        (4): MergeLayer()\n        (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n  )\n  (1): DecoderLayer(\n    (mhra): MultiHeadAttention(\n      (attention): Linear(in_features=768, out_features=2304, bias=True)\n      (out): Linear(in_features=768, out_features=768, bias=True)\n      (drop_att): Dropout(p=0.03, inplace=False)\n      (drop_res): Dropout(p=0.03, inplace=False)\n      (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    )\n    (ff): SequentialEx(\n      (layers): ModuleList(\n        (0): Linear(in_features=768, out_features=3072, bias=True)\n        (1): GeLU()\n        (2): Linear(in_features=3072, out_features=768, bias=True)\n        (3): Dropout(p=0.03, inplace=False)\n        (4): MergeLayer()\n        (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n  )\n  (2): DecoderLayer(\n    (mhra): MultiHeadAttention(\n      (attention): Linear(in_features=768, out_features=2304, bias=True)\n      (out): Linear(in_features=768, out_features=768, bias=True)\n      (drop_att): Dropout(p=0.03, inplace=False)\n      (drop_res): Dropout(p=0.03, inplace=False)\n      (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    )\n    (ff): SequentialEx(\n      (layers): ModuleList(\n        (0): Linear(in_features=768, out_features=3072, bias=True)\n        (1): GeLU()\n        (2): Linear(in_features=3072, out_features=768, bias=True)\n        (3): Dropout(p=0.03, inplace=False)\n        (4): MergeLayer()\n        (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n  )\n  (3): DecoderLayer(\n    (mhra): MultiHeadAttention(\n      (attention): Linear(in_features=768, out_features=2304, bias=True)\n      (out): Linear(in_features=768, out_features=768, bias=True)\n      (drop_att): Dropout(p=0.03, inplace=False)\n      (drop_res): Dropout(p=0.03, inplace=False)\n      (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    )\n    (ff): SequentialEx(\n      (layers): ModuleList(\n        (0): Linear(in_features=768, out_features=3072, bias=True)\n        (1): GeLU()\n        (2): Linear(in_features=3072, out_features=768, bias=True)\n        (3): Dropout(p=0.03, inplace=False)\n        (4): MergeLayer()\n        (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n  )\n), Sequential(\n  (0): DecoderLayer(\n    (mhra): MultiHeadAttention(\n      (attention): Linear(in_features=768, out_features=2304, bias=True)\n      (out): Linear(in_features=768, out_features=768, bias=True)\n      (drop_att): Dropout(p=0.03, inplace=False)\n      (drop_res): Dropout(p=0.03, inplace=False)\n      (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    )\n    (ff): SequentialEx(\n      (layers): ModuleList(\n        (0): Linear(in_features=768, out_features=3072, bias=True)\n        (1): GeLU()\n        (2): Linear(in_features=3072, out_features=768, bias=True)\n        (3): Dropout(p=0.03, inplace=False)\n        (4): MergeLayer()\n        (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n  )\n  (1): DecoderLayer(\n    (mhra): MultiHeadAttention(\n      (attention): Linear(in_features=768, out_features=2304, bias=True)\n      (out): Linear(in_features=768, out_features=768, bias=True)\n      (drop_att): Dropout(p=0.03, inplace=False)\n      (drop_res): Dropout(p=0.03, inplace=False)\n      (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    )\n    (ff): SequentialEx(\n      (layers): ModuleList(\n        (0): Linear(in_features=768, out_features=3072, bias=True)\n        (1): GeLU()\n        (2): Linear(in_features=3072, out_features=768, bias=True)\n        (3): Dropout(p=0.03, inplace=False)\n        (4): MergeLayer()\n        (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n  )\n  (2): DecoderLayer(\n    (mhra): MultiHeadAttention(\n      (attention): Linear(in_features=768, out_features=2304, bias=True)\n      (out): Linear(in_features=768, out_features=768, bias=True)\n      (drop_att): Dropout(p=0.03, inplace=False)\n      (drop_res): Dropout(p=0.03, inplace=False)\n      (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    )\n    (ff): SequentialEx(\n      (layers): ModuleList(\n        (0): Linear(in_features=768, out_features=3072, bias=True)\n        (1): GeLU()\n        (2): Linear(in_features=3072, out_features=768, bias=True)\n        (3): Dropout(p=0.03, inplace=False)\n        (4): MergeLayer()\n        (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n  )\n  (3): DecoderLayer(\n    (mhra): MultiHeadAttention(\n      (attention): Linear(in_features=768, out_features=2304, bias=True)\n      (out): Linear(in_features=768, out_features=768, bias=True)\n      (drop_att): Dropout(p=0.03, inplace=False)\n      (drop_res): Dropout(p=0.03, inplace=False)\n      (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    )\n    (ff): SequentialEx(\n      (layers): ModuleList(\n        (0): Linear(in_features=768, out_features=3072, bias=True)\n        (1): GeLU()\n        (2): Linear(in_features=3072, out_features=768, bias=True)\n        (3): Dropout(p=0.03, inplace=False)\n        (4): MergeLayer()\n        (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n  )\n), Sequential(\n  (0): PoolingLinearClassifier(\n    (layers): Sequential(\n      (0): BatchNorm1d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (1): Linear(in_features=2304, out_features=50, bias=True)\n      (2): ReLU(inplace=True)\n      (3): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (4): Dropout(p=0.1, inplace=False)\n      (5): Linear(in_features=50, out_features=5, bias=True)\n    )\n  )\n)], add_time=True, silent=False)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.freeze_to(-3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(2, slice(1e-6/(2.6**4),1e-5), moms=(0.8,0.7))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Single item predictions\nr1 = learn.predict(test_df.review[0])","execution_count":39,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Test set predictions\npreds, _ = learn.get_preds(ds_type=DatasetType.Test, ordered=True)\nratings = np.argmax(preds, 1)\nprint(min(ratings))","execution_count":51,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"stream","text":"tensor(0)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# 5. Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_preds = ratings + 1\nsubmission_df = pd.DataFrame({'review_id': test_df['review_id'], 'rating': submission_preds})\nsubmission_df.to_csv('submission.csv', header=True, index=False)","execution_count":52,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}